# 流式输出

- 为什么会考这道题？
  25年大厂必考题
  - llm 聊天机器人 23年AI爆款--> 24年AI推理-->25 AI Agent 年  都是AI产品
  - 流式输出 属于用户体验内容 前端职责所在
  
- 为什么要流式输出？
前端：
  - 数据边生成边输出：可以让我们更快地看到响应。

后端：
  - LLM 以 API 方式提供给我们？
    AIGenerticContent 生成式的大模型 一个token 一个 token transform (google) 出来的。
  - 比如，你问“你是谁？”
    它会先写出一个我,然后逐步推理：模型会根据上下文逐步预测下一个词（token），并不断更新概率分布。流式输出直接反映了这一过程，无需等待所有token生成完毕即可返回中间结果。
  - 

- 前端的职责
  - 良好的用户体验
  - 尽快反馈结果
  - 流式输出，障眼法？你看一个个字蹦出来的时候，ai也在一边计算，让你感觉就像是它早就知道答案。
  - 心理学：懂用户心理，让人感觉很高级，让你愿意花时间去等

- 步骤
  - 前端如何实现流式输出
    有一个setInterval 每一段时间去请求一次接口，a然后把数据输出到页面上，一直执行。简单的大模型一般用这个。
    setInterval 异步输出 -> 事件监听机制 message 

  - 后端如何实现流式输出
    socket 长链接
    http请求是基于请求响应式简单协议 把内容发给你后就会关闭连接
    http2.0中，支持server push 服务器可以主动推送数据给客户端，而不需要客户端发起请求。

- 全栈能力
    npm init -y   node后端项目初始化
    npm i express    老牌的 node框架

   