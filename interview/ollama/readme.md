# ollama

它是一个让你能通过简单命令，在本地轻松下载、运行和管理大语言模型的工具，支持GPU加速和类Open AI 接口，适合本地部署和开发。

Meta 公司的Llama 的羊驼模型

deepseek-r1:1.5b  
  1.5b：(1.5billion) 参数的尺寸
  Qwen 

  在11434 端口提供api的调用